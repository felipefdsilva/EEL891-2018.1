{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Aprendizado-de-Máquina-2018.2\">Aprendizado de Máquina 2018.2<a class=\"anchor-link\" href=\"#Aprendizado-de-Máquina-2018.2\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Trabalho-1---Estimando-o-preço-de-imóveis-com-técnicas-de-regressão-(competição-do-Kaggle)\">Trabalho 1 - Estimando o preço de imóveis com técnicas de regressão (competição do Kaggle)<a class=\"anchor-link\" href=\"#Trabalho-1---Estimando-o-preço-de-imóveis-com-técnicas-de-regressão-(competição-do-Kaggle)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Aluno: Felipe Ferreira da Silva</p>\n",
    "<p>Nome de Usuário no Kaggle: <strong>felipefdsilva</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Introdução\">Introdução<a class=\"anchor-link\" href=\"#Introdução\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Este trabalho tem como propósito a participação na competição Kaggle: \"House Prices: Advanced Regression Techniques\". Mais detalhes sobre a competição podem ser lidos no endereço: <a href=\"https://www.kaggle.com/c/house-prices-advanced-regression-techniques\">https://www.kaggle.com/c/house-prices-advanced-regression-techniques</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Em resumo, o dataset foi manipulado de forma a:</p>\n",
    "<ol>\n",
    "<li>remover outliers, </li>\n",
    "<li>normalizar a distribuição de valores da variável alvo</li>\n",
    "<li>normalizar a distribuição de preditores </li>\n",
    "<li>minimizar o número de colunas </li>\n",
    "<li>prencher campos vazios (\"NaN\") com o valor médio</li>\n",
    "<li>tratar variáveis categóricas através de one hot encoding.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Foram utilizados algumas os regressores:</p>\n",
    "<ol>\n",
    "<li>LinearRegression()</li>\n",
    "<li>RandomForest()</li>\n",
    "<li>GradientBoostingRegressor()</li>\n",
    "<li>ElasticNet</li>\n",
    "</ol>\n",
    "<p>Com o último apresentando o melhor resultado.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>O modelo foi testado através de regressão linear. Vários gráficos são exibidos ao longo do relatório para ilustrar e justificar as operações realizadas.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>O relatório foi escrito com auxilio da ferramenta Jupyter Notebook. Todo o código Python utilizado encontra-se aqui, com comentários explicativos para cada célula.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Importação-das-bibliotecas-necessárias\">Importação das bibliotecas necessárias<a class=\"anchor-link\" href=\"#Importação-das-bibliotecas-necessárias\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Foram utilizadas basicamente bibliotecas relacionada a plotagem de grÁficos, ferramentas matemáticas e de estatística, e bibliotecas scikit-learn para manipulação do dataset e criação dos modelos.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Configurações para o gráficos</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use(style='ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Importando-os-dados-e-convertendo-num-dataset-do-pandas\">Importando os dados e convertendo num dataset do pandas<a class=\"anchor-link\" href=\"#Importando-os-dados-e-convertendo-num-dataset-do-pandas\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_file = './train.csv'\n",
    "test_file = './test.csv'\n",
    "\n",
    "train_dataset = pd.read_csv(train_file)\n",
    "test_dataset = pd.read_csv(test_file)\n",
    "\n",
    "target = train_dataset.SalePrice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Com o código da célula abaixo, observa-se a formato dos dataset de treino e teste.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (train_dataset.shape)\n",
    "print (test_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observando o conteúdo de algumas colunas:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id='Estudando-a-variavel-alvo-\"SalePrice\"'>Estudando a variável alvo <strong>\"SalePrice\"</strong><a class=\"anchor-link\" href='#Estudando-a-variavel-alvo-\"SalePrice\"'>¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(target, color='blue');\n",
    "print(\"Skewness:\", target.skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observa-se pelo gráfico acima que a variável alvo (SalePrice) tem uma cauda longa para a direita. Modelos de regressão linear tem melhor comportamento quando trabalham com variáveis de distribuição normal. Portanto, fazemos uma trasformação logarítimica para aproximar SalePrice de uma gaussiana.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = np.log(target)\n",
    "sns.distplot(target, color='blue');\n",
    "print(\"Skewness: \", target.skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Lidando-com-variáveis-com-campos-vazios\">Lidando com variáveis com campos vazios<a class=\"anchor-link\" href=\"#Lidando-com-variáveis-com-campos-vazios\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observa-se com o código abaixo as características que possuem mais campos vazios no dataset, ordenadas de cima para baixo de acordo com o percentual de dados ausentes.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = train_dataset.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_dataset.isnull().sum()/train_dataset.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Escolhe-se descartar todas as colunas que possuem mais de 15% de dados faltando, por considerar este um valor suficientemente alto para desconsiderar o potencial preditivo dessas características.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.drop((missing_data[missing_data['Total'] > 81]).index, axis=1)\n",
    "test_dataset = test_dataset.drop((missing_data[missing_data['Total'] > 81]).index, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Lidando-com-variáveis-numéricas\">Lidando com variáveis numéricas<a class=\"anchor-link\" href=\"#Lidando-com-variáveis-numéricas\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = train_dataset.select_dtypes(include=[np.number])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Um vez destacada a parcela do dataset que contém colunas de dados numéricas, estuda-se a correlação destas colunas com a variavel alvo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = numeric_features.corr()\n",
    "\n",
    "print (corr['SalePrice'].sort_values(ascending=False)[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>De acordo com a descrição do dataset, \"MSSubClass\" é uma variável categórica e não numérica. Portanto, precisa de um cuidado especial. Por enquanto, será retirada do dataset numeric_features.</p>\n",
    "<p>Também serão retiradas as colunas 'SalePrice' e 'Id', para realização de plotagens.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = numeric_features.drop(['SalePrice', 'MSSubClass','Id'], axis=1)\n",
    "numeric_features_list = numeric_features.columns\n",
    "numeric_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Com os gráficos abaixo, observa-se a distribuição das medidas de cada variável, com o objetivo de encontrar outliers (pontos isolados que destoam da tendência da população e que tem potencial de prejudicar a modelagem).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 55))\n",
    "sns.set()\n",
    "for i in range(1, 34):\n",
    "    plt.subplot(12, 3, i)\n",
    "    sns.distplot(numeric_features[numeric_features_list[i-1]].dropna())\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(figsize=(22, 60))\n",
    "sns.set()\n",
    "for i in range(1, 34):\n",
    "    plt.subplot(12, 3, i)\n",
    "    sns.scatterplot(y='SalePrice', x=numeric_features[numeric_features_list[i-1]], data=train_dataset)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observando os grÃ¡ficos acima, decide-se por retirar colunas que possuem massiva concentraÃ§Ã£o de zeros, pois se a variÃ¡vel tem comportamento constante, nÃ£o influenciarÃ¡ no modelo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.drop(['BsmtFinSF2', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'LowQualFinSF', 'KitchenAbvGr'], axis=1)\n",
    "test_dataset = test_dataset.drop(['BsmtFinSF2', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'LowQualFinSF', 'KitchenAbvGr'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = numeric_features.drop(['BsmtFinSF2', '3SsnPorch', 'ScreenPorch','PoolArea', 'MiscVal', 'LowQualFinSF', 'KitchenAbvGr'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observa-se em escala maior algumas variáveis em que se faz necessária a remoção de <em>outliers</em>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5 id=\"TotalBsmt\">TotalBsmt<a class=\"anchor-link\" href=\"#TotalBsmt\">¶</a></h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(y='SalePrice', x='TotalBsmtSF', data=train_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5 id=\"LotArea\">LotArea<a class=\"anchor-link\" href=\"#LotArea\">¶</a></h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(y='SalePrice', x='LotArea', data=train_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5 id=\"GrLivArea\">GrLivArea<a class=\"anchor-link\" href=\"#GrLivArea\">¶</a></h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(y='SalePrice', x='GrLivArea', data=train_dataset);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5 id=\"GarageArea\">GarageArea<a class=\"anchor-link\" href=\"#GarageArea\">¶</a></h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(y='SalePrice', x='GarageArea', data=train_dataset);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Remove-se então, os outliers com as operações abaixo:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset[train_dataset['TotalBsmtSF'] < 2500]\n",
    "train_dataset = train_dataset[train_dataset['LotArea'] < 100000]\n",
    "train_dataset = train_dataset[train_dataset['GrLivArea'] < 3000]\n",
    "train_dataset = train_dataset[train_dataset['GarageArea'] < 1000]\n",
    "train_dataset = train_dataset[train_dataset['1stFlrSF'] < 2300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>A etapa abaixo é uma parte do trabalho em que não houve sucesso. Se buscou transformar alguns preditores para aproximá-los também da gaussiana. As transformações se resumiram as colunas com assimetria maior que 75%. Utilizou-se a transformação de Box-cox, com lambda escolhido empiricamente. Porém, as previsões do modelo com tais medições geraram erros maiores quando submetidas no Kaggle.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skewed_feats = numeric_features.apply(lambda x: x.dropna().skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkew in features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skewed_features = list(skewness[skewness['Skew'] > 0.75].index)\n",
    "lmbda = 0.15\n",
    "print (\"Feature\", \"\\t\", \"Original Skewness\", \"\\t\", \"Skewness after Box-cox transformation\\n\")\n",
    "for feat in skewed_features:\n",
    "    print (feat, \"\\t\", numeric_features[feat].skew(), \"\\t\", (boxcox1p(numeric_features[feat], lmbda)).skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Como alguns colunas se distanciaram a distribuição normal, estas foram retiradas da transformação, pois entende-se que a transformação, nestes casos, prejudicava o modelo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in ['BsmtHalfBath', 'EnclosedPorch', 'TotalBsmtSF', 'BsmtUnfSF']:\n",
    "    skewed_features.remove(col)\n",
    "\n",
    "for feat in skewed_features:\n",
    "#    train_dataset[feat] = boxcox1p(numeric_features[feat], lmbda)\n",
    "#    test_dataset[feat] = boxcox1p(numeric_features[feat], lmbda)\n",
    "    print (feat, \"\\t\", numeric_features[feat].skew(), \"\\t\", (boxcox1p(numeric_features[feat], lmbda)).skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Retornando a coluna \"MSSubClass\", que deve ser transformada em coluna de dados categóricos para ser tratada corretamente. Foram criadas siglas de acordo com a descrição do dataset para cada valor numérico. Cada sigla agora é uma categoria de MSSubClass.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#20 \t1-STORY 1946 & NEWER ALL STYLES  \t(NAL)\n",
    "#30 \t1-STORY 1945 & OLDER  \t(OLD)\n",
    "#40 \t1-STORY W/FINISHED ATTIC ALL AGES  \t(SFAAT)\n",
    "#45 \t1-1/2 STORY - UNFINISHED ALL AGES  \t(SUAA)\n",
    "#50 \t1-1/2 STORY FINISHED ALL AGES (SFAA)\n",
    "#60 \t2-STORY 1946 & NEWER  \t(SN)\n",
    "#70 \t2-STORY 1945 & OLDER  \t(SO)\n",
    "#75 \t2-1/2 STORY ALL AGES  \t(SAG)\n",
    "#80 \tSPLIT OR MULTI-LEVEL  \t(SML)\n",
    "#85 \tSPLIT FOYER  \t(SF)\n",
    "#90 \tDUPLEX - ALL STYLES AND AGES  \t(DASA)\n",
    "#120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER  \t(OneSPUD)\n",
    "#150\t1-1/2 STORY PUD - ALL AGES  \t(HalfSPUD)\n",
    "#160\t2-STORY PUD - 1946 & NEWER  \t(TwoSPUD)\n",
    "#180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER  \t(PUDMultilvl)\n",
    "#190\t2 FAMILY CONVERSION - ALL STYLES AND AGES \t(FamConv)\n",
    "\n",
    "def categorize_MSSubClass(x):\n",
    "    if x == 20:\n",
    "        return 'NAL'\n",
    "    if x == 30:\n",
    "        return 'OLD'\n",
    "    if x == 40:\n",
    "        return 'SFAAT'\n",
    "    if x == 45:\n",
    "        return 'SUAA'\n",
    "    if x == 50:\n",
    "        return 'SFAA'\n",
    "    if x == 60:\n",
    "        return 'SN'\n",
    "    if x == 70:\n",
    "        return 'SO'\n",
    "    if x == 80:\n",
    "        return 'SML'\n",
    "    if x == 85:\n",
    "        return 'SF'\n",
    "    if x == 90:\n",
    "        return 'DASA'\n",
    "    if x == 120:\n",
    "        return 'OneSPUD'\n",
    "    if x == 150:\n",
    "        return 'HalfSPUD'\n",
    "    if x == 160:\n",
    "        return 'TwoSPUD'\n",
    "    if x == 180:\n",
    "        return 'PUDMultilvl'\n",
    "    if x == 190:\n",
    "        return 'FamConv'\n",
    "    \n",
    "train_dataset['cat_MSSubClass'] = train_dataset.MSSubClass.apply(categorize_MSSubClass)\n",
    "test_dataset['cat_MSSubClass'] = test_dataset.MSSubClass.apply(categorize_MSSubClass)\n",
    "\n",
    "test_dataset['cat_MSSubClass'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>A saída acima confirma a transformação, com a criação da nova coluna \"cat_MSSubClass\".</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Lidando-com-variáveis-categóricas\">Lidando com variáveis categóricas<a class=\"anchor-link\" href=\"#Lidando-com-variáveis-categóricas\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Em suma, apenas observa-se o comportamento das varáveis e estuda-se como mapeá-las em valores numéricos.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categoric_features = train_dataset.select_dtypes(include='object')\n",
    "categoric_features_list = categoric_features.columns\n",
    "print (\"Shape:\", categoric_features.shape, '\\n')\n",
    "print (\"Estas sÃ£o as colunas categÃ³ricas: \", categoric_features.columns,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Na célula abaixo, adiciona-se a categoria \"MISSING\" para que seja possível gerar gráficos de todas as variáveis caategóricas, inclusive as que possuem valores NaN.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat in categoric_features_list:\n",
    "    categoric_features[feat] = categoric_features[feat].astype('category')\n",
    "    if categoric_features[feat].isnull().any():\n",
    "        categoric_features[feat] = categoric_features[feat].cat.add_categories(['MISSING'], inplace=False)\n",
    "        categoric_features[feat] = categoric_features[feat].fillna('MISSING')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "\n",
    "f = pd.melt(train_dataset, id_vars = ['SalePrice'], value_vars=categoric_features_list)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, height=5)\n",
    "g = g.map(boxplot, \"value\", \"SalePrice\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Observa-se que a coluna \"SaleCondition\" em especial, existe um valor('Partial') que destoa do restante, possuindo uma relação com preços mais elevados. Portanto, decide-se codificar a coluna como se segue, convertendo os valores \"Partial\" em '1's e o restantes em zeros.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode(x): return 1 if x == 'Partial' else 0\n",
    "train_dataset['enc_SaleCondition'] = train_dataset.SaleCondition.apply(encode)\n",
    "test_dataset['enc_SaleCondition'] = test_dataset.SaleCondition.apply(encode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Já no caso de Street, obeserva-se que a mesma é uma variÃ¡vel binária (a rua é pavimentada ou não). Portanto, codifica-se como se segue:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset['enc_street'] = pd.get_dummies(train_dataset.Street, drop_first=True)\n",
    "test_dataset['enc_street'] = pd.get_dummies(test_dataset.Street, drop_first=True)\n",
    "\n",
    "train_dataset['enc_street'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Pode-se realizar o mesmo procedimento para \"Utilities\" (uma variável que indica as utilidades suportadas pela casa: gás, eletricidade e água). Porém, observando a distribuição de seus valores, chega-se a conclusão que é uma coluna descartável.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(train_dataset['Utilities'].value_counts(), '\\n')\n",
    "print(test_dataset['Utilities'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Nota-se que, no dataset de treino só há um valor \"NoSeWa\"(Eletricidade e Gás apenas). No dataset de teste só há casa com todas as utilidades (AllPub). Portanto, 'Utilities' pode ser descartado.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.drop(['Utilities'], axis = 1)\n",
    "test_dataset = test_dataset.drop(['Utilities'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Criamos colunas binárias para o restante das colunas categóricas, mapeando cada categoria em uma nova coluna binária.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohe_train_dataset = pd.get_dummies(train_dataset)\n",
    "ohe_test_dataset = pd.get_dummies(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(ohe_train_dataset.shape)\n",
    "print(ohe_test_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>O Comando abaixo alinhas os dois datasets, para que regressor receba as mesmas colunas e na mesma ordem nos dois casos.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Ajuste-final\">Ajuste final<a class=\"anchor-link\" href=\"#Ajuste-final\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Por fim, iremos remover todas as colunas que possuem correlação menor que 7% com a variável alvo. Este valor foi escolhido empiricamente.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_list = []\n",
    "for key, value in ohe_train_dataset.corr()['SalePrice'].items():\n",
    "    if abs(value) < 0.07 and key != \"Id\":\n",
    "        drop_list.append(key)\n",
    "\n",
    "final_train_dataset = ohe_train_dataset.drop(drop_list, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = np.log(final_train_dataset.SalePrice)\n",
    "X = final_train_dataset.drop(['SalePrice'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test = X.align(ohe_test_dataset, join='left', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Construindo-o-modelo\">Construindo o modelo<a class=\"anchor-link\" href=\"#Construindo-o-modelo\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Representamos os preditores usados para regressão como o vetor X e a variável alvo como y.</p>\n",
    "<p>Utilizaremos o regressor ElasticNet, pois este foi o que apresentou melhor resultado. O segundo melhor resultado foi obtido com o regressor linear. Também foram testados os regressores Floresta Randômica e Gradient Boosting, que apresentaram resultados mais distantes dos dois primeiros.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_pipeline = make_pipeline(Imputer(), ElasticNet(alpha=0.0005, l1_ratio=.9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Retirando a coluna 'Id' de X_train para o teste de validação cruzada. A coluna 'Id' será retirada de X_test algumas células abaixo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.drop(['Id'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Testando-o-modelo-com-validação-cruzada-e-RMSE-e-MAE\">Testando o modelo com validação cruzada e RMSE e MAE<a class=\"anchor-link\" href=\"#Testando-o-modelo-com-validação-cruzada-e-RMSE-e-MAE\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>A função cross_val_score do scikit-learn trabalha apenas com erro quadrático médio negativo, assim como erro absoluto médio negativo. Portanto, para termos o RMSE, é preciso realizar algumas operações matemáticas.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = [sqrt(-1*x) for x in cross_val_score(my_pipeline, X_train, y, scoring='neg_mean_squared_error')]\n",
    "print(scores,'\\n')\n",
    "\n",
    "print (\"MÃ©dia:\", np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>O erro absoluto médio é calculado abaixo:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(my_pipeline, X_train, y, scoring='neg_mean_absolute_error')\n",
    "print(scores*(-1),'\\n')\n",
    "\n",
    "print (\"MÃ©dia:\", np.mean(scores)*(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Fazendo-as-previsões-com-o-arquivo-de-teste-e-gerando-o-arquivo-csv-para-submissão\">Fazendo as previsões com o arquivo de teste e gerando o arquivo csv para submissão<a class=\"anchor-link\" href=\"#Fazendo-as-previsões-com-o-arquivo-de-teste-e-gerando-o-arquivo-csv-para-submissão\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Criando o dataset \"submission\" que terá apenas duas colunas: \"Id\" e \"SalePrice\"</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = X_test.Id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Retirando a coluna \"Id\" do dataset de teste para realizar as previsões.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = X_test.drop(['Id'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Preenchendo os campos vazios do dataset de teste.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_imputer = Imputer()\n",
    "my_imputer.fit_transform(X_train)\n",
    "final_test = my_imputer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Gerando as previsões</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_pipeline.fit(X_train, y)\n",
    "predictions = my_pipeline.predict(final_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Aplicando a exponencial em 'SalePrice' para anular a transformação feita anteriormente.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_predictions = np.exp(predictions)\n",
    "submission['SalePrice'] = final_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Finalmente, na célula abaixo, gera-se o arquivo que será submetido no Kaggle.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
